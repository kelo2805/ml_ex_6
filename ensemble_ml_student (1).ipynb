{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "20d99f03",
      "metadata": {
        "id": "20d99f03"
      },
      "source": [
        "# **Ensemble methods**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a36f6509",
      "metadata": {
        "id": "a36f6509"
      },
      "source": [
        "# Iris Dataset\n",
        "\n",
        "Il dataset Iris è un classico dataset nell'apprendimento automatico e nella statistica, introdotto da Ronald Fisher nel 1936. È comunemente utilizzato per attività di classificazione e clustering.\n",
        "\n",
        "## Caratteristiche e Struttura\n",
        "- **Campioni**: 150 campioni di fiori iris.\n",
        "- **Features**:\n",
        "  - Lunghezza del sepalo (cm)\n",
        "  - Larghezza del sepalo (cm)\n",
        "  - Lunghezza del petalo (cm)\n",
        "  - Larghezza del petalo (cm)\n",
        "- **Classi (Etichette Target)**:\n",
        "  - *Iris-setosa*\n",
        "  - *Iris-versicolor*\n",
        "  - *Iris-virginica*\n",
        "\n",
        "Ogni classe è rappresentata da 50 campioni.\n",
        "\n",
        "## Caratteristiche Principali\n",
        "- **Balanced Dataset**: Ogni classe contiene lo stesso numero di campioni.\n",
        "- **Perfect for Beginners**: a sua semplicità e struttura ben definita lo rendono perfetto per scopi didattici.\n",
        "- **Separable Classes**:\n",
        "  - *Iris-setosa* è linearmente separabile dalle altre due classi.\n",
        "  - *Iris-versicolor* e *Iris-virginica* sono più difficili da separare tra loro.\n",
        "\n",
        "\n",
        "# Iris Dataset Classes\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <th>Iris Setosa</th>\n",
        "        <th>Iris Versicolor</th>\n",
        "        <th>Iris Virginica</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td><img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSFn-u9Lagrv8pV4zJ8Z1cEqXNL_uo39CrL6A&s\" alt=\"Iris setosa\" width=\"300\" height=\"300\"></td>\n",
        "        <td><img src=\"https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcSJqxUtJiLfMX5aIoyPTPz7rMdjxgWagMlBzt0QbfATKzRqH4XnMMDN5aBrU1FvRt19jkHMOrIefjywQlDg9rOeKC6JbA72Wf--jqHD-g\" alt=\"Iris versicolor\" alt=\"Iris versicolor\" width=\"300\" height=\"300\"></td>\n",
        "        <td><img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSQbTwTLA7_7SeTE3B1QOKw0TlB8Rp6NU7vyg&s\" alt=\"Iris virginica\" width=\"300\" height=\"300\"></td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "891a70d4",
      "metadata": {
        "id": "891a70d4"
      },
      "source": [
        "# `plot_decision_boundary` Function\n",
        "\n",
        "La funzione `plot_decision_boundary` permette di visualizzare i margini decisionali di un classificatore. In questo modo è possibile visualizzare come il modello distingue le feature di campioni assegnati a classi diverse.\n",
        "\n",
        "1. **Parametri**:\n",
        "    - `clf`: Il classificatore allenato che ha il metodo `predict`.\n",
        "    - `X`: La matrice dei dati di input, per cui si assume una dimensione 2D per la visualizzazione.\n",
        "    - `y`: Le labels corrispondenti ai dati `X`.\n",
        "\n",
        "2. **Output**:\n",
        "    - Un grafico 2D contenente:\n",
        "        - **Features**: `Feature 1` e `Feature 2` lungo l' asse x e y (se è stata usata PCA, queste sono le 2 componenti).\n",
        "        - **Regioni decisionali**: Colori diversi indicano regioni classificate come labels diverse.\n",
        "        - **Camponi**: I punti del dataset (`X`) sono sovrapposti alle regioni e colorati in base alla loro label corretta (`y`).\n",
        "\n",
        "### **Sintassi**\n",
        "\n",
        "```python\n",
        "plot_decision_boundary(trained_model, X_data, y_data)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0062646f",
      "metadata": {
        "id": "0062646f"
      },
      "outputs": [],
      "source": [
        "# Helper function to create the plot\n",
        "# and visualize the decision boundary\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def plot_decision_boundary(clf, X, y):\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 500), np.linspace(y_min, y_max, 500))\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.RdYlBu)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap=plt.cm.RdYlBu)\n",
        "    plt.title(\"Decision Boundary Visualization\")\n",
        "    plt.xlabel(\"Feature 1\")\n",
        "    plt.ylabel(\"Feature 2\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5184bd53",
      "metadata": {
        "id": "5184bd53"
      },
      "source": [
        "## Funzione `train_test_split()` :\n",
        "\n",
        "---\n",
        "\n",
        "## **train_test_split()**\n",
        "\n",
        "La funzione `train_test_split()` è parte del modulo `sklearn.model_selection`. Viene utilizzata per dividere un dataset in training e test set.\n",
        "\n",
        "\n",
        "### **Esempio**:\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training data: {len(X_train)} samples\")\n",
        "print(f\"Testing data: {len(X_test)} samples\")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ccb9a84",
      "metadata": {
        "id": "8ccb9a84"
      },
      "source": [
        "# **Esercizio 1: Classifichiamo il dataset Iris con un DecisionTree**\n",
        "\n",
        "Eseguire tutti gli step di preparazione per l' allenamento di un DecisionTree. Per lo split dai dati in training e test utilizzare:\n",
        "\n",
        "- `test_size` = `0.3`\n",
        "\n",
        "- `random_state` = `42`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ded18e38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ded18e38",
        "outputId": "d91e165a-9596-4955-b1f5-53c65e2235ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data: 105 samples\n",
            "Testing data: 45 samples\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# svolgimento...\n",
        "(X_train, X_test, y_train, y_test)=train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "print(f\"Training data: {len(X_train)} samples\")\n",
        "print(f\"Testing data: {len(X_test)} samples\")\n",
        "\n",
        "#Standardizzazione\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "# Decision Tree\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train_pca, y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1452eca5",
      "metadata": {
        "id": "1452eca5"
      },
      "source": [
        "# **Eesercizio 2: Implementare ensamble methods**\n",
        "\n",
        "Una volta allenato il DecisionTree nell' esercizio 1, vogliamo applicarvi i metodi di ensamble. Nello specifico andremo a implementare:\n",
        "\n",
        "* **AdaBoost**\n",
        "* **Bagging**\n",
        "* **Random Forest**\n",
        "\n",
        "Di seguito vediamo la sintassi di ognuno di questi."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "222b2e08",
      "metadata": {
        "id": "222b2e08"
      },
      "source": [
        "## 1. **AdaBoostClassifier**:\n",
        "\n",
        "L' `AdaBoostClassifier` crea un insieme di alberi decisionali deboli. Assegna un peso a ciascun albero e li combina per formare un modello più robusto.\n",
        "\n",
        "### Example:\n",
        "```python\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# Train the model\n",
        "ada_clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=50, random_state=42)\n",
        "ada_clf.fit(X_train, y_train)\n",
        "\n",
        "# Get predictions\n",
        "predictions = ada_clf.predict(X_test)\n",
        "\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 2. **RandomForestClassifier**:\n",
        "\n",
        "Il `RandomForestClassifier` costruisce più alberi in parallelo e combina i loro risultati per migliorare l'accuratezza.\n",
        "\n",
        "### Example:\n",
        "```python\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Train the model\n",
        "rf_clf = RandomForestClassifier(n_estimators=10, max_depth=3, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Get predictions\n",
        "predictions = rf_clf.predict(X_test)\n",
        "\n",
        "```\n",
        "\n",
        "#### **N.B. RandomForest non richiede come argomento il classificatore, differentemente dagli altri metodi.**\n",
        "\n",
        "---\n",
        "\n",
        "## 3. **BaggingClassifier**:\n",
        "\n",
        "Il `BaggingClassifier` combina molteplici modelli base (come DecisionTree) utilizzando la tecnica del bootstrapping per ridurre la varianza.\n",
        "\n",
        "### Example:\n",
        "```python\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "# Train the model\n",
        "bag_clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
        "bag_clf.fit(X_train, y_train)\n",
        "\n",
        "# Get predictions\n",
        "predictions = bag_clf.predict(X_test)\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6c29229",
      "metadata": {
        "id": "c6c29229"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Creare gli oggetti ensemble\n",
        "\n",
        "# svolgimento...\n",
        "\n",
        "\n",
        "# Allenare i modelli\n",
        "\n",
        "# svolgimento...\n",
        "\n",
        "\n",
        "# Valutare e stampare le prestazioni dei modelli\n",
        "\n",
        "# svolgimento...\n",
        "\n",
        "base_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "\n",
        "#  AdaBoost\n",
        "adaboost = AdaBoostClassifier(base_estimator=base_tree, n_estimators=50, learning_rate=1.0, random_state=42)\n",
        "adaboost.fit(X_train_pca, y_train)\n",
        "y_pred_adaboost = adaboost.predict(X_test_pca)\n",
        "\n",
        "#  Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "rf.fit(X_train_pca, y_train)\n",
        "y_pred_rf = rf.predict(X_test_pca)\n",
        "\n",
        "\n",
        "#  Bagging\n",
        "bagging = BaggingClassifier(base_estimator=base_tree, n_estimators=50, random_state=42)\n",
        "bagging.fit(X_train_pca, y_train)\n",
        "y_pred_bagging = bagging.predict(X_test_pca)\n",
        "\n",
        "\n",
        "\n",
        "# 7. Valutazione\n",
        "print(\"\\n Bagging Accuracy:\", accuracy_score(y_test, y_pred_bagging))\n",
        "print(classification_report(y_test, y_pred_bagging))\n",
        "\n",
        "print(\"\\n Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "print(\"\\n AdaBoost Accuracy:\", accuracy_score(y_test, y_pred_adaboost))\n",
        "print(classification_report(y_test, y_pred_adaboost))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78e9035c",
      "metadata": {
        "id": "78e9035c"
      },
      "source": [
        "# Funzioni utili per Ensemble Models\n",
        "\n",
        "---\n",
        "\n",
        "## **1. Hard Voting tra tre classificatori**\n",
        "\n",
        "### **Descrizione**:\n",
        "Combina le predizioni da tre classificatori selezionando la casse più votata per ogni campione.\n",
        "\n",
        "### **Parametri**:\n",
        "- `pred1` (numpy array): Predizioni del classificatore 1.\n",
        "- `pred2` (numpy array): Predizioni del classificatore 2.\n",
        "- `pred3` (numpy array): Predizioni del classificatore 3.\n",
        "\n",
        "### **Output**:\n",
        "- Restituisce un numpy array conenente la classe più votata per ogni campione.\n",
        "\n",
        "### **Sintassi**:\n",
        "```python\n",
        "voted = hard_voting(pred1_test, pred2_test, pred3_test)\n",
        "print(\"Hard Voting Predictions:\", voted)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## **2. Allineare predizioni a più classi**\n",
        "\n",
        "### **Descrizione**:\n",
        "Allinea le probabilità in modo da rendere compatibili diversi subsets quando vengono combinati.\n",
        "\n",
        "### **Parametri**:\n",
        "- `pred` (numpy array): Probabilità predette da un classificatore.\n",
        "- `classes_present` (list): Classi conosciute dal classificatore.\n",
        "- `n_classes` (int, optional): Numero totale di classe, default è 3.\n",
        "\n",
        "### **Output**:\n",
        "- Ritorna un numpy array con le proabilità allineate tra tutte le classi\n",
        "- Returns a numpy array with probabilities aligned across all classes.\n",
        "\n",
        "### **Sintassi**:\n",
        "```python\n",
        "aligned_probs = align_predictions(pred, [0, 1], n_classes=3)\n",
        "print(\"Aligned Probabilities:\", aligned_probs)\n",
        "\n",
        "Matrice originale [[0.7, 0.3], [0.4, 0.6]]\n",
        "diventa\n",
        "Matrice allineata [[0.7, 0, 0.3], [0.4, 0, 0.6]]\n",
        "\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## **3. Plot Decision Boundary**\n",
        "\n",
        "### **Descrizione**:\n",
        "Visualizza i margini decisionali per vari ensamble methods, inclusi `expert1`, `expert2`, `expert3`, `base`, `soft_voting`, `hard_voting`, e `gating`.\n",
        "\n",
        "### **Parametri**:\n",
        "- `X` (numpy array): Dati per la visualizzazione (2D).\n",
        "- `y` (numpy array): Lables originali.\n",
        "- `clf1`, `clf2`, `clf3` (classifiers, optional): Esperti usati per calcolare prediction.\n",
        "- `base` (classifier, optional): Classificatore base.\n",
        "- `mode` (string): Metodo di ensamble per la visualizzazione. I valori possibili sono: `\"expert1\"`, `\"expert2\"`, `\"expert3\"`, `\"base\"`, `\"soft_voting\"`, `\"hard_voting\"`, `\"gating\"`.\n",
        "\n",
        "\n",
        "### **Output**:\n",
        "- Displays a decision boundary plot for the selected mode.\n",
        "\n",
        "### **Usage**:\n",
        "```python\n",
        "plot_decision_boundary(x_test, y_test, expert1=expert1, clf2=expert2, clf3=expert3, base=base_network, mode=\"soft_voting\")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f27abad",
      "metadata": {
        "id": "9f27abad"
      },
      "source": [
        "# **Esercizio 3: Implementare Mixture of Experts**\n",
        "\n",
        "Nel seguente esercizio vogliamo implementare un meccanismo di Mixture of Experts. Poichè in iris sono presenti 3 classi, vogliamo allenare 3 classificatori (cioè 3 esperi), rispettivamente:\n",
        "\n",
        "- esperto 1: riconosce tra la classe 0 e la classe 1.\n",
        "- esperto 2: riconosce tra la classe 0 e la classe 2.\n",
        "- esperto 3: riconosce tra la classe 1 e la classe 2.\n",
        "\n",
        "Infine utilizzare la funzione `plot_modes` per plottare le diverse modalità."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45ffeeeb",
      "metadata": {
        "id": "45ffeeeb"
      },
      "outputs": [],
      "source": [
        "def hard_voting(pred1, pred2, pred3):\n",
        "    combined = np.vstack([pred1, pred2, pred3]).T\n",
        "    voted = []\n",
        "    for sample in combined:\n",
        "        counts = np.bincount(sample)\n",
        "        most_common_label = counts.argmax()\n",
        "        voted.append(most_common_label)\n",
        "    return np.array(voted)\n",
        "\n",
        "def align_predictions(pred, classes_present, n_classes=3):\n",
        "    aligned = np.zeros((len(pred), n_classes))\n",
        "    for idx, class_label in enumerate(classes_present):\n",
        "        aligned[:, class_label] = pred[:, idx]\n",
        "    return aligned\n",
        "\n",
        "def plot_modes(X, y, clf1=None, clf2=None, clf3=None, base=None, mode=\"expert1\"):\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 500),\n",
        "                         np.linspace(y_min, y_max, 500))\n",
        "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "    if mode.startswith(\"expert\"):\n",
        "        expert_map = {\n",
        "            \"expert1\": (clf1, [0, 1]),\n",
        "            \"expert2\": (clf2, [0, 2]),\n",
        "            \"expert3\": (clf3, [1, 2]),\n",
        "        }\n",
        "        clf, classes = expert_map[mode]\n",
        "        Z = clf.predict(grid).reshape(xx.shape)\n",
        "        title = f\"Decision Boundary - {mode.capitalize()}\"\n",
        "\n",
        "    elif mode == \"base\":\n",
        "        Z = base.predict(grid).reshape(xx.shape)\n",
        "        title = \"Decision Boundary - Base Network\"\n",
        "\n",
        "    elif mode == \"soft_voting\":\n",
        "        Z1 = align_predictions(clf1.predict_proba(grid), [0, 1])\n",
        "        Z2 = align_predictions(clf2.predict_proba(grid), [0, 2])\n",
        "        Z3 = align_predictions(clf3.predict_proba(grid), [1, 2])\n",
        "        Z = (Z1 + Z2 + Z3).argmax(axis=1).reshape(xx.shape)\n",
        "        title = \"Decision Boundary - Soft Voting\"\n",
        "\n",
        "    elif mode == \"hard_voting\":\n",
        "        Z1 = clf1.predict(grid)\n",
        "        Z2 = clf2.predict(grid)\n",
        "        Z3 = clf3.predict(grid)\n",
        "        Z = np.array([Z1, Z2, Z3])\n",
        "        Z = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=Z)\n",
        "        Z = Z.reshape(xx.shape)\n",
        "        title = \"Decision Boundary - Hard Voting\"\n",
        "\n",
        "    elif mode == \"gating\":\n",
        "        gating_weights = base.predict_proba(grid)\n",
        "        gating_weights /= gating_weights.sum(axis=1, keepdims=True)\n",
        "        Z1 = align_predictions(clf1.predict_proba(grid), [0, 1])\n",
        "        Z2 = align_predictions(clf2.predict_proba(grid), [0, 2])\n",
        "        Z3 = align_predictions(clf3.predict_proba(grid), [1, 2])\n",
        "        Z = gating_weights * Z1 + gating_weights * Z2 + gating_weights * Z3\n",
        "        Z = Z.argmax(axis=1).reshape(xx.shape)\n",
        "        title = \"Decision Boundary - Mixture of Experts (Gating)\"\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown mode: {mode}\")\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.RdYlBu)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap=plt.cm.RdYlBu)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Feature 1\")\n",
        "    plt.ylabel(\"Feature 2\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "610f8315",
      "metadata": {
        "id": "610f8315"
      },
      "outputs": [],
      "source": [
        "# Caricare il dataset Iris\n",
        "\n",
        "# svolgimento...\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Split del dataset in training e test set\n",
        "\n",
        "# svolgimento...\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# Applicare lo scaling e PCA\n",
        "\n",
        "# svolgimento...\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# PCA con 2 componenti\n",
        "pca = PCA(n_components=2)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Creare 3 modelli di Decision Tree, ognuno dovrà essere esperto in una coppia di classi\n",
        "# N.B. ogni esperto dovrà essere allenato su un sottoinsieme contentente solo\n",
        "# le classi di competenza\n",
        "\n",
        "# svolgimento...\n",
        "# Esperti: (0 vs 1), (0 vs 2), (1 vs 2)\n",
        "expert_cl_pairs = [(0, 1), (0, 2), (1, 2)]\n",
        "experts = []\n",
        "\n",
        "for cls1, cls2 in expert_cl_pairs:\n",
        "    mask = np.isin(y_train, [cls1, cls2])\n",
        "    X_sub = X_train[mask]\n",
        "    y_sub = y_train[mask]\n",
        "    clf = DecisionTreeClassifier(random_state=42)\n",
        "    clf.fit(X_sub, y_sub)\n",
        "    experts.append(clf)\n",
        "\n",
        "\n",
        "\n",
        "# Creare un modello di Decision Tree che funge da base network\n",
        "# N.B. il base network dovrà essere allenato su tutte le classi, sarà la nostra gating network\n",
        "\n",
        "# svolgimento...\n",
        "base = DecisionTreeClassifier(random_state=42)\n",
        "base.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Estrarre le predizione di ogni esperto sul test set.\n",
        "# N.B. Vogliamo le probabilità di appartenenza a ciascuna classe, quindi useremo `predict_proba`. Inoltre\n",
        "# ogni esperto riporterà solo le classi di competenza, quindi dovremo allineare le predizioni.\n",
        "\n",
        "# svolgimento...\n",
        "# Funzione per mappare le probabilità sull'intero spazio a 3 classi\n",
        "def align_proba(proba, known_classes):\n",
        "    aligned = np.zeros((proba.shape[0], 3))\n",
        "    for i, cls in enumerate(known_classes):\n",
        "        aligned[:, cls] = proba[:, i]\n",
        "    return aligned\n",
        "\n",
        "expert_probs = []\n",
        "for i, (cls1, cls2) in enumerate(expert_cl_pairs):\n",
        "    proba = experts[i].predict_proba(X_test)\n",
        "    aligned = align_proba(proba, [cls1, cls2])\n",
        "    expert_probs.append(aligned)\n",
        "\n",
        "\n",
        "\n",
        "# Estrarre le predizioni del base network sul test set\n",
        "\n",
        "# svolgimento...\n",
        "pred_base = base.predict_proba(X_test)\n",
        "\n",
        "\n",
        "# Usiamo hard voting per combinare le predizioni degli esperti.\n",
        "# N.B. hard voting significa che ogni esperto vota per la sua classe di competenza e il voto più comune\n",
        "# vince.\n",
        "\n",
        "# svolgimento...\n",
        "# Ogni esperto fa una predizione solo sulle sue classi -> majority voting\n",
        "votes = np.zeros((X_test.shape[0], 3), dtype=int)\n",
        "for i, (cls1, cls2) in enumerate(expert_cl_pairs):\n",
        "    pred = experts[i].predict(X_test)\n",
        "    for j, p in enumerate(pred):\n",
        "        votes[j, p] += 1\n",
        "\n",
        "hard_voting_preds = np.argmax(votes, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "# Usiamo soft voting per combinare le predizioni degli esperti.\n",
        "# N.B. soft voting significa che il voto di ogni esperto ha lo stesso peso.\n",
        "\n",
        "# svolgimento...\n",
        "soft_avg = np.mean(expert_probs, axis=0)\n",
        "soft_voting_preds = np.argmax(soft_avg, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "# Usiamo gating network per combinare le predizioni degli esperti.\n",
        "# N.B. la gating network calcola le probabilità di appartenenza a ciascuna classe e le usa per pesare\n",
        "# le predizioni degli esperti.\n",
        "\n",
        "# svolgimento...\n",
        "weighted_sum = np.zeros_like(pred_base)\n",
        "for i in range(3):  # class index\n",
        "    weighted_sum += pred_base[:, [i]] * np.stack([probs[:, i] for probs in expert_probs], axis=1).mean(axis=1).reshape(-1, 1)\n",
        "\n",
        "gating_preds = np.argmax(weighted_sum, axis=1)\n",
        "\n",
        "\n",
        "modes = [\"expert1\", \"expert2\", \"expert3\", \"base\", \"soft_voting\", \"hard_voting\", \"gating\"]\n",
        "\n",
        "# Plottare le decision boundaries per ogni modalità.\n",
        "\n",
        "# svolgimento...\n",
        "for mode in modes:\n",
        "    plot_modes(X_test_pca, y_test, clf1=experts[0], clf2=experts[1], clf3=experts[2], base=base, mode=mode)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}